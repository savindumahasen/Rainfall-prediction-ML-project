{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://host.docker.internal:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Rainfall-predictions-ML-project</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x14779f40cb0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Import the  pyspark libraries adn create the pyspark session\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.appName('Rainfall-predictions-ML-project').getOrCreate()\n",
    "spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+--------+-------+-----------+-------+--------+--------+-----+--------+-------------+---------+--------+\n",
      "| id|day|pressure|maxtemp|temparature|mintemp|dewpoint|humidity|cloud|sunshine|winddirection|windspeed|rainfall|\n",
      "+---+---+--------+-------+-----------+-------+--------+--------+-----+--------+-------------+---------+--------+\n",
      "|  0|  1|  1017.4|   21.2|       20.6|   19.9|    19.4|    87.0| 88.0|     1.1|         60.0|     17.2|       1|\n",
      "|  1|  2|  1019.5|   16.2|       16.9|   15.8|    15.4|    95.0| 91.0|     0.0|         50.0|     21.9|       1|\n",
      "|  2|  3|  1024.1|   19.4|       16.1|   14.6|     9.3|    75.0| 47.0|     8.3|         70.0|     18.1|       1|\n",
      "|  3|  4|  1013.4|   18.1|       17.8|   16.9|    16.8|    95.0| 95.0|     0.0|         60.0|     35.6|       1|\n",
      "|  4|  5|  1021.8|   21.3|       18.4|   15.2|     9.6|    52.0| 45.0|     3.6|         40.0|     24.8|       0|\n",
      "|  5|  6|  1022.7|   20.6|       18.6|   16.5|    12.5|    79.0| 81.0|     0.0|         20.0|     15.7|       1|\n",
      "|  6|  7|  1022.8|   19.5|       18.4|   15.3|    11.3|    56.0| 46.0|     7.6|         20.0|     28.4|       0|\n",
      "|  7|  8|  1019.7|   15.8|       13.6|   12.7|    11.8|    96.0|100.0|     0.0|         50.0|     52.8|       1|\n",
      "|  8|  9|  1017.4|   17.6|       16.5|   15.6|    12.5|    86.0|100.0|     0.0|         50.0|     37.5|       1|\n",
      "|  9| 10|  1025.4|   16.5|       14.4|   12.0|     8.6|    77.0| 84.0|     1.0|         50.0|     38.3|       0|\n",
      "| 10| 11|  1016.8|   16.3|       15.3|   14.1|    14.0|    97.0|100.0|     0.0|         40.0|     24.4|       1|\n",
      "| 11| 12|  1012.5|   16.2|       15.2|   14.0|    12.4|    98.0|100.0|     0.0|         50.0|     23.5|       1|\n",
      "| 12| 13|  1020.4|   15.0|       15.5|   13.2|    12.0|    77.0| 86.0|     0.0|         50.0|     32.4|       1|\n",
      "| 13| 14|  1012.5|   13.5|       12.9|   11.6|    11.8|    87.0| 92.0|     0.0|         50.0|     37.0|       1|\n",
      "| 14| 15|  1018.4|   17.8|       16.5|   15.1|    12.1|    77.0| 85.0|     1.2|         40.0|     20.9|       1|\n",
      "| 15| 16|  1024.3|   15.3|       12.9|   10.0|    11.2|    79.0| 91.0|     0.3|         20.0|     20.0|       1|\n",
      "| 16| 17|  1022.5|   16.3|       13.1|   11.4|     2.0|    79.0| 70.0|     6.8|         20.0|     30.3|       1|\n",
      "| 17| 18|  1034.6|   17.5|       16.2|   14.1|    11.8|    68.0| 60.0|     2.5|         50.0|     13.4|       0|\n",
      "| 18| 19|  1024.1|   16.8|       15.8|   14.0|    12.9|    76.0| 77.0|     0.0|         20.0|     20.5|       1|\n",
      "| 19| 20|  1020.2|   16.4|       14.2|   12.7|    11.6|    75.0| 93.0|     0.1|         40.0|     21.9|       1|\n",
      "+---+---+--------+-------+-----------+-------+--------+--------+-----+--------+-------------+---------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Read the train set\n",
    "df_train_set=spark.read.csv('train.csv',header=True,inferSchema=True)\n",
    "df_train_set.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- pressure: double (nullable = true)\n",
      " |-- maxtemp: double (nullable = true)\n",
      " |-- temparature: double (nullable = true)\n",
      " |-- mintemp: double (nullable = true)\n",
      " |-- dewpoint: double (nullable = true)\n",
      " |-- humidity: double (nullable = true)\n",
      " |-- cloud: double (nullable = true)\n",
      " |-- sunshine: double (nullable = true)\n",
      " |-- winddirection: double (nullable = true)\n",
      " |-- windspeed: double (nullable = true)\n",
      " |-- rainfall: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## check the data types of each column in dataset\n",
    "df_train_set.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'day',\n",
       " 'pressure',\n",
       " 'maxtemp',\n",
       " 'temparature',\n",
       " 'mintemp',\n",
       " 'dewpoint',\n",
       " 'humidity',\n",
       " 'cloud',\n",
       " 'sunshine',\n",
       " 'winddirection',\n",
       " 'windspeed',\n",
       " 'rainfall']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## check the column names\n",
    "df_train_set.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'isnull'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## check the null values\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mdf_train_set\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misnull\u001b[49m()\n",
      "File \u001b[1;32mc:\\Users\\THIS PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyspark\\sql\\dataframe.py:3129\u001b[0m, in \u001b[0;36mDataFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   3096\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the :class:`Column` denoted by ``name``.\u001b[39;00m\n\u001b[0;32m   3097\u001b[0m \n\u001b[0;32m   3098\u001b[0m \u001b[38;5;124;03m.. versionadded:: 1.3.0\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3126\u001b[0m \u001b[38;5;124;03m+---+\u001b[39;00m\n\u001b[0;32m   3127\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[1;32m-> 3129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m   3130\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name)\n\u001b[0;32m   3131\u001b[0m     )\n\u001b[0;32m   3132\u001b[0m jc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jdf\u001b[38;5;241m.\u001b[39mapply(name)\n\u001b[0;32m   3133\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Column(jc)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'isnull'"
     ]
    }
   ],
   "source": [
    "## check \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
